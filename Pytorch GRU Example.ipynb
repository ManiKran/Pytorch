{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yDM6eUWnwkqS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "LjYYXueax0h6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size=28\n",
        "sequence_length=28\n",
        "num_layers=2\n",
        "hidden_size=256\n",
        "num_classes=10\n",
        "learning_rate=0.001\n",
        "batch_size=64\n",
        "num_epochs=2"
      ],
      "metadata": {
        "id": "5wz9v-oIyF1z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "    super(RNN, self).__init__()\n",
        "    self.hidden_size=hidden_size\n",
        "    self.num_layers=num_layers\n",
        "    self.gru=nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "    self.fc= nn.Linear(hidden_size*sequence_length, num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    h0=torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "    out, _ =self.gru(x,h0)\n",
        "    out=out.reshape(out.shape[0],-1)\n",
        "    out=self.fc(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "0XGNXApS-riH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=datasets.MNIST(root='dataaet/', train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_loader= DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataset= datasets.MNIST(root='dataset/', train=False, transform=transforms.ToTensor(), download=True)\n",
        "test_loader= DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "p2q2gEEVynd1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=RNN(input_size, hidden_size, num_layers, num_classes).to(device)"
      ],
      "metadata": {
        "id": "FdvR-JQm1oly"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "xlPcf-r5114H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "    data=data.to(device=device).squeeze(1)\n",
        "    targets=targets.to(device=device)\n",
        "\n",
        "    scores=model(data)\n",
        "    loss=criterion(scores, targets)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    "
      ],
      "metadata": {
        "id": "ujTFYT1i2V7C"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(loader, model):\n",
        "  num_correct=0\n",
        "  num_samples=0\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for x,y in loader:\n",
        "      x=x.to(device=device).squeeze(1)\n",
        "      y=y.to(device=device)\n",
        "\n",
        "      scores=model(x)\n",
        "      _, predictions= scores.max(1)\n",
        "      num_correct+= (predictions==y).sum()\n",
        "      num_samples+= predictions.size(0)\n",
        "\n",
        "    print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
        "\n",
        "  model.train()"
      ],
      "metadata": {
        "id": "hczv8kRN3Hkt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_accuracy(train_loader, model)\n",
        "check_accuracy(test_loader, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9N3xkF542QI",
        "outputId": "ecd0716b-e753-404e-dfd3-4fdc915e8150"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 58601 / 60000 with accuracy 97.67\n",
            "Got 9735 / 10000 with accuracy 97.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "gE9gF1wU4-Wu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}